# Hybrid BERT4Rec Recommender System

This project implements a hybrid version of BERT4Rec for sequential recommendation, integrating both categorical metadata and BERT-based title embeddings to improve item representations.

---

## üìÅ Project Structure

```plaintext
Final_project/
‚îú‚îÄ‚îÄ BERT4Rec_model.py              # Category-only BERT4Rec
‚îú‚îÄ‚îÄ BERT4Rec_hybrid_title.py       # Full hybrid model with title embeddings
‚îú‚îÄ‚îÄ config.py                      # Global configuration settings
‚îú‚îÄ‚îÄ data_preprocessing.py          # Data loader and train/val splitter
‚îú‚îÄ‚îÄ embed_titles.py                # Precompute BERT title vectors
‚îú‚îÄ‚îÄ evaluate.py                    # Evaluation (Recall@k, NDCG@k)
‚îú‚îÄ‚îÄ generate_submission.py         # Generate submission.csv for Kaggle
‚îú‚îÄ‚îÄ main.py                        # Training/evaluation script
‚îú‚îÄ‚îÄ plot.py                        # Training curve and metric visualizations
‚îú‚îÄ‚îÄ train.py                       # Model training loop
‚îú‚îÄ‚îÄ data_set/                      # Input data (train.csv, test.csv, item_meta.csv)
‚îú‚îÄ‚îÄ preprocessed_data/             # Saved sequences and embeddings
‚îî‚îÄ‚îÄ results/                       # Model outputs and submissions (separated by model type)
```

---

## üß† Models

### Supported Architectures

- `category`: BERT4Rec + item ID + category embedding
- `hybrid_title`: BERT4Rec + item ID + category + BERT title embedding

Select model using:

```bash
python main.py --model category
```

or

```bash
python main.py --model hybrid_title
```

> For `hybrid_title`, the title embeddings will be automatically generated.

All results are saved to subfolders in `results/{model_type}/`.

---

## üìã Requirements

- Python 3.6+
- PyTorch (>= 1.6)
- pandas
- numpy
- matplotlib
- scikit-learn
- sentence_transformers
- tqdm

---

## üõ†Ô∏è Setup

```bash
pip install torch pandas numpy matplotlib scikit-learn sentence_transformers tqdm
```

### Run on GPU (Optional)

To train this module on a GPU, ensure that `CUDA` and `cuDNN` are installed on your device. Once installed, use the following command to install the appropriate version of PyTorch:

```bash
python -m pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu{version_number}
```

Replace `{version_number}` with the version of CUDA installed on your system.

For example, with `CUDA` version `12.8.1` and `cuDNN` version `9.8.0`, the command would be:

```bash
python -m pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128
```

**Note:** All training for this project was conducted on a GPU.

---

## üöÄ Usage

### 1. Preprocess Data & Train Model

```bash
python main.py --model hybrid_title
```

### 2. Generate Submission

```bash
python generate_submission.py --model hybrid_title
```

---

## üìä Output

Results and logs are saved to `results/hybrid_title/`:

- `submission.csv` ‚Äî predictions for top-10 items per user
- `model_metrics.json` ‚Äî final Recall/NDCG@k values
- `model_performance.json` ‚Äî epoch-wise training/val loss & metrics
- `metrics_at_k.png` ‚Äî evaluation metrics plot

---

## üî¨ Evaluation Metrics

- **Recall@K**: Was the correct item among the top K?
- **NDCG@K**: Rank-sensitive score for recommended list

---

## üìå Notes

- Truncates or pads user sequences to 20 items (Config.SEQ_LEN)
- Supports metadata from `item_meta.csv` (main_category + title)
- Trained using masked item prediction (MLM-style BERT loss)
- Results directory is dynamically selected based on `--model` type

---

## üß© Future Improvements

- Incorporate additional metadata (e.g., brand, price)
- Test with LightGCN and ensemble methods
- Add real-time inference pipeline for deployment

---
